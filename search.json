[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "Our data set contains information on every fatal shooting made by a police officer in the US. This data was initially collected since the FBI and the Centers for Disease Control and Prevention log fatal shootings by police, but officials acknowledge that their data is incomplete. To combat this, our dataset aims to create a more comprehensive picture of police shootings, in what cases they come about, and which demographic groups these shootings tend to involve.\nWe are using data from fatal-police-shootings-data.csv with 14 variables:\nOur dataset was fairly clean when we found it, making it relatively easy to interpret and work with. However, our “Race” variable is given by letters - A, W, H, B, N, and O - so are making an extra column “Race_Full” that has the full names of these variables such as “Asian” instead of “A” and “Native American” instead of “N”.\nThe cleaned data could be found here: Download the cleaning script"
  },
  {
    "objectID": "data.html#rubric-on-this-page",
    "href": "data.html#rubric-on-this-page",
    "title": "Data",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nDescribe where/how to find data.\n\nYou must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\nWhy was the data collected/curated? Who put it together? (This is important, if you don’t know why it was collected then that might not be a good dataset to look at.\n\nDescribe the different data files used and what each variable means.\n\nIf you have many variables then only describe the most relevant ones and summarize the rest.\n\nDescribe any cleaning you had to do for your data.\n\nYou must include a link to your load_and_clean_data.R file.\nRrename variables and recode factors to make data more clear.\nAlso, describe any additional R packages you used outside of those covered in class.\nDescribe and show code for how you combined multiple data files and any cleaning that was necessary for that.\nSome repetition of what you do in your load_and_clean_data.R file is fine and encouraged if it helps explain what you did.\n\nOrganization, clarity, cleanliness of the page\n\nMake sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\nThis page should be self-contained."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Race and Policing",
    "section": "",
    "text": "The Big Question:\nDo states with higher populations of people of color experience more fatal police shootings?\nIn recent years, the issue of police shootings, particularly those involving people of color, has sparked intense debate across the U.S. But what if the frequency of these shootings is not just about individual cases or isolated incidents? What if the location and demographics of each state play a significant role? This project explores how the proportion of people of color in each state may influence the rate of fatal police shootings. It’s a conversation that is essential for understanding systemic issues within policing, and it’s a story you’ll explore through interactive data and compelling visualizations.\nOur research suggests that there’s a connection: states with higher proportions of people of color tend to see more fatal police shootings. But we’re not just telling you that—this project lets you explore that question in detail through data, and gives you the tools to understand this important issue for yourself.\n\n\nHow You Can Explore the Data:\nWe’ve created interactive maps that let you compare the racial makeup of each state with the number of fatal police shootings. It’s an easy way to visually understand the connection between race and police violence. Here’s how to engage:\n\nMap 1: Proportion of People of Color This map shows the percentage of people of color in each state. The darker the state, the higher the proportion of people of color living there.\nMap 2: Fatal Police Shootings This map shows the total number of fatal police shootings by state. Again, darker states represent those with more shootings.\n\nYou can click on any state to get the exact numbers and compare them side by side. Do states with high proportions of people of color also have high numbers of police shootings? What patterns emerge as you explore the maps?\nThese interactive tools give you the power to see for yourself how race and policing are connected across the U.S.\n\n\n\n\nA Deeper Look:\nTo add more context, we’ve also created a detailed figure that breaks down fatal police shootings by race, adjusted for population size. This means you can see which racial groups experience the most fatal police shootings relative to their size in the population.\n\nFatal Police Shootings by Race (Adjusted for Population Proportion): This chart organizes racial groups from highest to lowest in terms of fatal shootings, giving you a clearer picture of who is most affected when taking population size into account. The chart shows the stark disparities in how different racial groups are impacted by police violence.\n\n\n\n\n\nWhy It Matters:\nThis is more than just data—it’s about understanding the larger picture. Our findings raise critical questions about the role that race plays in policing. By exploring this data, you can see firsthand how systemic issues affect different communities. It’s not just about statistics; it’s about real lives, real people, and the urgent need for reform.\nBy engaging with this project, you’re not just learning about data; you’re learning about the real-world implications of race and policing in America. It’s a chance to reflect, ask tough questions, and, most importantly, think about how we can create a more just society for everyone.\nSo, why should you care?\nBecause this issue affects all of us. Understanding the correlation between race and police shootings is crucial to pushing for meaningful change. By engaging with this project, you’re diving into an important conversation about race, justice, and equality in America.\nExplore the data, draw your own conclusions, and become part of the conversation."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a website for the final project for MA415 Data Science with R by Team Thirteen The members of this team are below."
  },
  {
    "objectID": "about.html#sumtung-lo",
    "href": "about.html#sumtung-lo",
    "title": "About",
    "section": "Sumtung Lo",
    "text": "Sumtung Lo\nSumtung is a Senior in Economic&Mathematics. Her Github page is: https://github.com/sumtunglo"
  },
  {
    "objectID": "about.html#marissa-alfieri",
    "href": "about.html#marissa-alfieri",
    "title": "About",
    "section": "Marissa Alfieri",
    "text": "Marissa Alfieri\nMarissa is a Junior studying Psychology and Education & Human Development with a minor in Statistics. Her Github page is: https://github.com/marissa-alfieri"
  },
  {
    "objectID": "about.html#sara-patel",
    "href": "about.html#sara-patel",
    "title": "About",
    "section": "Sara Patel",
    "text": "Sara Patel\nSara is a Junior in Data Science with a minor in Innovation & Entreprenuership. Her GitHub page is: https://github.com/SaraPatel0"
  },
  {
    "objectID": "about.html#weizhao-liu",
    "href": "about.html#weizhao-liu",
    "title": "About",
    "section": "Weizhao Liu",
    "text": "Weizhao Liu\nWeizhao is a Senior in Apllied Math. His Github page is: https://github.com/Weizhao-Liu"
  },
  {
    "objectID": "about.html#uyen-chu",
    "href": "about.html#uyen-chu",
    "title": "About",
    "section": "Uyen Chu",
    "text": "Uyen Chu\nUyen is a Sophmore majoring in Biology and minoring in CS. Her GitHub is https://github.com/uchu04"
  },
  {
    "objectID": "dataset/State_maps.html",
    "href": "dataset/State_maps.html",
    "title": "State-Level Heatmaps of POC Proportion and Total Cases",
    "section": "",
    "text": "Shiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "posts/2024-12-04-blog-post-7/blog-post-7.html",
    "href": "posts/2024-12-04-blog-post-7/blog-post-7.html",
    "title": "Blog Post 7",
    "section": "",
    "text": "How are we continuing our exploratory data analysis? We are deepening our exploratory data analysis by analyzing interaction between race, gender, age, and situational factors like threat level and armed status, adjusted for population proportion. Additionally, we are merging external dataset, such as the Giffords Law Center’s gun law scorecard, to explore the correlation between gun legislation and shooting rates. Visualizations, including an interactive map highlighting state level trends and disparities, are developed to enhance insights. Based on the EDA we have done so far, we got the most significant insight when comparing police shootings and racial proportions by state. To further delve into this analysis, we plan to make an interactive map using the shiny package. This visual will include two maps of the United States. The first will give insight about the frequency of fatal police shootings by population per state, while the second will have the population proportion of various racial groups where the viewer can choose which race to look into. Having these two maps side-by-side allows the user to see overlaps in how race interacts with shootings in the form of a map.\nOur Thesis Police shootings occur more frequently in states with higher proportions of people of color, specifically Black, Native American, and Hispanic people.\nHow we plan to refine our visualizations and tables? We are adjusting our dataset to include summary statistics of race populations in each state. This will allow for visualizations that are relevant to the frequency of police brutality in relation to race and a broad comparison between states. We plan to further polish our existing visuals by adding applicable axis titles, captions for clarity, color codes, and annotations when necessary. All of these changes serve to make our visualizations and tables easier to understand and draw insight from."
  },
  {
    "objectID": "posts/2024-11-05-blog-post-4/blog-post-4.html",
    "href": "posts/2024-11-05-blog-post-4/blog-post-4.html",
    "title": "Blog Post 4",
    "section": "",
    "text": "Our initial analysis explored the breakdown of fatal shootings by race, gender, and age group, revealing several key trends. For instance, the data shows that White, non-Hispanic and Black, non-Hispanic individuals make up the largest groups affected by fatal police shootings. However, we’re questioning whether these numbers truly represent trends or are a result of data availability bias. To clarify, we plan to examine these racial breakdowns as proportions to see if disparities exist beyond the raw numbers. In terms of gender, our data indicates a significant imbalance, with males overwhelmingly represented among the victims. While this disparity is notable on its own, we’re also interested in exploring intersections with other factors, such as age or race, to see if these intersections provide additional insight into gender-based trends. For age, the most affected groups fall between 31-40, followed by 21-30 and 41-50, which may reflect broader demographic patterns or unique dynamics within police interactions. We’ll examine how age intersects with other variables to gain a more comprehensive understanding. When examining the data, we see that there is an overwhelming number of police shootings involving White and male victims. If we take a closer look (Figure 1), we notice that the proportion of males and females who are shot varies based on race . This means that there are trends across races where we see women make up a larger, albeit still tiny, proportion of those shot.\nFor Figure 2 in this week’s analysis, we included a bar chart illustrating the number of fatal shootings by race, adjusted to reflect each racial group’s proportion of the U.S. population. This will help identify potential over-representation and give a clearer picture of any disparities. The bar chart illustrating the number of fatal police shootings by race, adjusted to reflect each racial group’s proportion of the U.S. population indicates that Black individuals have the highest proportion of fatal shootings when adjusted for population size, highlighting a critical area of concern. Conversely, the adjusted figures show that White individuals now represent one of the lowest proportions among the groups analyzed, a stark contrast to previous findings. This adjustment underscores the importance of considering population proportions when analyzing fatal police shootings, as it significantly alters the interpretation of racial disparities and calls for a deeper investigation into the underlying factors contributing to these trends.\nFigure 3 presents the results of the logistic regression model, which examines the relationship between signs of mental illness and the manner of death (e.g., “shot” vs. “shot and Tasered”). The analysis suggests that individuals with mental illness may be more likely to be shot rather than shot and Tasered, implying that police officers may use less force (such as a Taser) when they do not perceive a significant mental health crisis or threat. Conversely, the majority of cases involving “shot and Tasered” appear to involve individuals without identifiable signs of mental illness. This trend raises important questions about how mental illness status might influence police decision-making in high-stress situations, potentially reflecting a differential response based on perceived threat levels. The findings underscore the need for further investigation into how mental health awareness and training for law enforcement could impact outcomes in such encounters.\n\n\n\nFigure 1\n\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 3"
  },
  {
    "objectID": "posts/2024-10-18-blog-post-2-/blog-post-2-.html",
    "href": "posts/2024-10-18-blog-post-2-/blog-post-2-.html",
    "title": "Blog Post 2",
    "section": "",
    "text": "After receiving feedback about our data sets from Prof. Sussman, we decided to take a closer look at Data Set 1. The data was collected by the U.S. Department of Education as a comprehensive data set of college characteristics, enrollment, aid, costs, and student outcomes of all U.S. institutions from 1996-2023. The file contains separate csv files for each year which will pose a potential issue because there is so much data. In addition, it is very hard to interpret all of the variable names in the csv file. From what we could tell, there is data about proportions of admissions, average income after graduation, tuition costs, debt/loans taken, and demographic details partitioned between male and female students/applicants. There are also a lot of N/A fields in the data that would require extra cleaning and interpretation.\nThe College Scorecard has two separate data sets, one for institution characteristics, and broken down by field study at each institution."
  },
  {
    "objectID": "posts/2024-10-23-blog-post-3/blog-post-3.html",
    "href": "posts/2024-10-23-blog-post-3/blog-post-3.html",
    "title": "Blog Post 3",
    "section": "",
    "text": "Our team, after exploring the data from the U.S. Department of Education for the College Scorecard that was presented in Blog Post 2, decided to shift to a new dataset. The previous one had data spanning years and covered institutional characteristics, enrollment, student aid, and student outcomes of colleges across the U.S. However, the data was dispersed across many files - one for each year from 1996 to 2023 - and was very inconsistent across yearly datasets. Specifically, there were dozens of null columns in earlier sets that were filled in for later ones, making it difficult to see how certain factors change over time. Overall, this dataset on student completion, debt and repayment, earnings, and more was very inconsistent and scattered, making it difficult for us to use and draw insight from.\nWe have since shifted to a dataset on fatal police shootings that is much more cohesive. This dataset has 14 columns and 5.4K rows, and contains information on every fatal shooting made by a police officer in the US. Some variables include race, whether the victim was armed, their age, gender, and location. This data was initially collected since the FBI and the Centers for Disease Control and Prevention log fatal shootings by police, but officials acknowledge that their data is incomplete. The dataset is able to be loaded and cleaned but seems to have some entries missing race data on victims. There are some possible biases to think about - this dataset may contain more shootings that were digitally documented and therefore officers felt pressure to record the instance officially. This means that there may be events that were not recorded with a camera or an audio device, so nobody knew to document the instance other than the offensive officer who may not want it on record.\nWith this data, we would like to draw insight on how race, gender, and age play into fatal police shooting trends.\n\n\n\nRace Image\n\n\n\n\n\nGender Image\n\n\n\n\n\nAge Image"
  },
  {
    "objectID": "posts/2024-11-11-blog-post-5/blog-post-5.html",
    "href": "posts/2024-11-11-blog-post-5/blog-post-5.html",
    "title": "Blog Post 5",
    "section": "",
    "text": "For our second dataset, we chose Giffords Law Center’s 2022 Scorecard, which uses a grading system to rank the states. The data is updated annually with a ranking that considers factors like background checks, firearm restrictions, and regulation of assault weapons. All fifty states are ranked based on thirty policy approaches to regulating guns and ammunition. States received points for stronger laws and lost points for weaker laws.\nOur idea is to combine data sets that relate to the access of guns in each state with the intention of analyzing how strict gun laws correlate to how much gun violence there is for the state in our original data set. A possible method of doing this is to create a new merged data set by reading the individual csv files and mutating new columns for the data that is relevant to our analysis. We have downloaded the scorecard file on gun policy strictness and are currently working merging the datasets in RStudio so that we can start our initial exploratory analysis.\nHere is a link to the website where we pulled our data from: https://brady-score.github.io/"
  },
  {
    "objectID": "posts/2024-11-16-blog-post-6/blog-post-6.html",
    "href": "posts/2024-11-16-blog-post-6/blog-post-6.html",
    "title": "Blog Post 6",
    "section": "",
    "text": "We began by merging our datasets, but encountered an issue with the state columns, which were inconsistent between the two datasets. The original dataset used state abbreviations, while the Brady Score dataset used full state names. To resolve this, we created a new column in the original dataset that combined both the full state names and their abbreviations. This allowed us to join the datasets on the newly created column for consistency. During the cleaning process, we also removed several columns that were not relevant to our analysis, including ‘Flee’, ‘id’, ‘body_camera’, and ‘officer name’. These columns were either redundant or unnecessary for our investigation. Additionally, we identified and corrected a couple of issues with the state data. For example, “DC” was mistakenly treated as a separate state, but it was merged into Maryland’s total since Washington, D.C. should be part of Maryland’s statistics. Similarly, Nevada (NV) appeared as two separate entries in our dataset, so we consolidated these rows to ensure they reflected the correct totals for Nevada. Finally, we removed any extra or incomplete rows that may have been left over from previous cleaning steps, ensuring that the dataset only contains valid and complete data for our analysis. This process ensured that our dataset was consistent and ready for further analysis.\nIn this analysis, we first explored the distribution of gender counts by state, visualizing the male and female population in each state using a side-by-side bar plot. We then examined the relationship between murders with firearms and population by state through a scatter plot, highlighting how firearm-related murders correlate with state population size. Finally, we built a linear regression model to predict murders with firearms, and visualized the model’s performance by plotting the actual vs. predicted values. This comparison allowed us to assess how well the model’s predictions align with the observed data, providing insight into its accuracy and potential areas for improvement.\n\n\n\nFigure 1\n\n\n\n\n\nFigure 2\n\n\n Additional Analysis:\nArmed vs Unarmed Cases by State (Top 15): California leads with the highest number of both armed and unarmed cases, followed by Texas and Florida. Across all states, armed cases significantly outnumber unarmed cases, showing a consistent pattern regardless of state size or location. \nMental Illness Cases vs Total Cases by State: There’s a clear positive correlation - as total cases increase, mental illness cases also increase. California stands as an outlier with both the highest total and mental illness cases, while most states cluster together with fewer than 200 total cases and 50 mental illness cases. \nPercentage of Female Cases by State (Top 20): The data shows a striking gender disparity across all states, with female cases making up only 4-7% of total cases. Georgia leads with the highest percentage of female cases, but even there, males account for over 93% of all cases."
  },
  {
    "objectID": "posts/2024-10-09-blog-post-1-/blog-post-1-.html",
    "href": "posts/2024-10-09-blog-post-1-/blog-post-1-.html",
    "title": "Blog Post 1",
    "section": "",
    "text": "Data set 1\nU.S. Department of Education: College Scorecard https://collegescorecard.ed.gov/data/\nThe U.S. Department of Education’s College Scorecard dataset provides comprehensive data on institutions of higher education, aiming to enhance transparency regarding student outcomes and institutional characteristics. The dataset comprises 174 columns and 214,886 rows, covering data from the 1996-97 to the 2022-23 academic years. It includes institution-level data, such as enrollment, student aid, costs, and outcomes, and field of study-level data that provides insights on debt at graduation and earnings one year post-graduation. Originally collected to help prospective students make informed choices, the dataset highlights disparities in education related to race, socio-economic status, debt accumulation, and federal funding distribution. Although the data can be cleaned and loaded, its large size may present challenges in analysis.\nData set 2\nAge-by-Race Specific Crime Rates, 1965-1985: [United States] https://catalog.data.gov/dataset/age-by-race-specific-crime-rates-1965-1985-united-states-b16aa\nIt is not clear in the description how many rows and columns there are in the dataset, but the variables are categorized into 4 subgroups per race and age over a 21 year time frame. The data was collected by the FBI “Uniform Crime Reports: Crime in the United States” and was aggregated. Using this data, we can answer questions that relate age-by-race crime to crime rates over 21 years. We can also take into account current events of the 1960s-1980s to consider if specific age cohorts had more reported crime rates. For example, we can consider the Baby Boom era and relate it to crime rates post WW2. We can also see which types of crimes were most committed by age-race group per period of time and see if this data is reflective of national crime trends. A challenge I foresee is being able to synthesize categorized data like this in the most effective way. A way to combat this is to focus on a specific crime across the 21 year time frame and analyze the relationship between age-by-race subgroups rather than try to understand many different variables of the same category all at once.\nData set 3\nData Police shootings https://www.kaggle.com/datasets/mrmorj/data-police-shootings?resource=download\nThis dataset has 14 columns and 5.4K rows, and contains information on every fatal shooting made by a police officer in the US. Some variables include race, whether the victim was armed, age, gender, and location. This data was initially collected since the FBI and the Centers for Disease Control and Prevention log fatal shootings by police, but officials acknowledge that their data is incomplete. The dataset is able to be loaded and cleaned but seems to have some entries missing race data on victims, which might be a problem. With this information, we would like to draw insight on how race, gender, and age play into fatal police shooting trends."
  },
  {
    "objectID": "dataset/merging_dataset.html",
    "href": "dataset/merging_dataset.html",
    "title": "Group Thirteen: MA [46]15 Final Project",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\nlibrary(readr)\n\n\ncleaned_fatal_police_shootings &lt;- read_csv(\"dataset/cleaned_fatal_police_shootings.csv\")\n\nRows: 5416 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): name, manner_of_death, armed, gender, race, city, state, threat_l...\ndbl   (2): id, age\nlgl   (2): signs_of_mental_illness, body_camera\ndate  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbrady_table &lt;- read_csv(\"dataset/US_Gun_Statistics_Full_Data.csv\")\n\nRows: 50 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): state\ndbl (6): raw_score, murders, murders_with_firearms, active_shooter_deaths, s...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncleaned_fatal_police_shootings &lt;- cleaned_fatal_police_shootings |&gt;\n  mutate(state = recode(state,\n                        \"AL\" = \"Alabama\", \n                        \"AK\" = \"Alaska\", \n                        \"AZ\" = \"Arizona\", \n                        \"AR\" = \"Arkansas\",\n                        \"CA\" = \"California\",\n                        \"CO\" = \"Colorado\", \n                        \"CT\" = \"Connecticut\", \n                        \"DE\" = \"Delaware\",\n                        \"FL\" = \"Florida\", \n                        \"GA\" = \"Georgia\", \n                        \"HI\" = \"Hawaii\", \n                        \"ID\" = \"Idaho\",\n                        \"IL\" = \"Illinois\", \n                        \"IN\" = \"Indiana\", \n                        \"IA\" = \"Iowa\", \n                        \"KS\" = \"Kansas\",\n                        \"KY\" = \"Kentucky\", \n                        \"LA\" = \"Louisiana\", \n                        \"ME\" = \"Maine\", \n                        \"MD\" = \"Maryland\",\n                        \"MA\" = \"Massachusetts\", \n                        \"MI\" = \"Michigan\", \n                        \"MN\" = \"Minnesota\", \n                        \"MS\" = \"Mississippi\",\n                        \"MO\" = \"Missouri\", \n                        \"MT\" = \"Montana\", \n                        \"NE\" = \"Nebraska\", \n                        \"NH\" = \"New Hampshire\",\n                        \"NJ\" = \"New Jersey\", \n                        \"NM\" = \"New Mexico\", \n                        \"NY\" = \"New York\",\n                        \"NV\" = \"Nevada\",\n                        \"NC\" = \"North Carolina\", \n                        \"ND\" = \"North Dakota\", \n                        \"OH\" = \"Ohio\", \n                        \"OK\" = \"Oklahoma\",\n                        \"OR\" = \"Oregon\", \n                        \"PA\" = \"Pennsylvania\", \n                        \"RI\" = \"Rhode Island\",\n                        \"SC\" = \"South Carolina\", \n                        \"SD\" = \"South Dakota\", \n                        \"TN\" = \"Tennessee\",\n                        \"TX\" = \"Texas\", \n                        \"UT\" = \"Utah\", \n                        \"VT\" = \"Vermont\", \n                        \"VA\" = \"Virginia\",\n                        \"WA\" = \"Washington\", \n                        \"WV\" = \"West Virginia\", \n                        \"WI\" = \"Wisconsin\", \n                        \"WY\" = \"Wyoming\",\n                        \"DC\" = \"Maryland\"))\n\nstate_shootings_summary &lt;- cleaned_fatal_police_shootings |&gt;\n  group_by(state) |&gt;\n  summarize(\n    total_cases = n(),                                  \n    total_armed = sum(armed != \"unarmed\", na.rm = TRUE), \n    total_unarmed = sum(armed == \"unarmed\", na.rm = TRUE),\n    avg_age = mean(age, na.rm = TRUE),                    \n    male_count = sum(gender == \"M\", na.rm = TRUE),        \n    female_count = sum(gender == \"F\", na.rm = TRUE),     \n    mental_illness_cases = sum(signs_of_mental_illness, na.rm = TRUE), \n    .groups = \"drop\")\n\nbrady_table &lt;- brady_table |&gt;\n  distinct(state, .keep_all = TRUE)\n\nmerged_data &lt;- state_shootings_summary |&gt;\n  full_join(brady_table, by = \"state\") \n\nwrite_csv(merged_data, \"dataset/merged_dataset.csv\")\n\n\n# Create the race_summary dataframe\nrace_summary &lt;- cleaned_fatal_police_shootings |&gt;\n  group_by(state) |&gt;\n  summarize(\n    total_cases = n(),\n    count_Black = sum(Race_Full == \"Black, non-Hispanic\", na.rm = TRUE),\n    count_Hispanic = sum(Race_Full == \"Hispanic\", na.rm = TRUE),\n    count_Asian = sum(Race_Full == \"Asian\", na.rm = TRUE),\n    count_Native_American = sum(Race_Full == \"Native American\", na.rm = TRUE),\n    count_Other = sum(Race_Full == \"Other\", na.rm = TRUE),\n    count_White = sum(Race_Full == \"White, non-Hispanic\", na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Now calculate the race-specific proportions\nrace_summary &lt;- race_summary |&gt;\n  mutate(\n    proportion_Black = `count_Black` / total_cases,\n    proportion_Hispanic = `count_Hispanic` / total_cases,\n    proportion_Asian = `count_Asian` / total_cases,\n    proportion_Native_American = `count_Native_American` / total_cases,\n    proportion_Other = `count_Other` / total_cases,\n    proportion_White = `count_White` / total_cases,\n    POC_Proportion = (\n      `count_Black` +\n      `count_Hispanic` +\n      `count_Asian` +\n      `count_Native_American` +\n      `count_Other`\n    ) / total_cases\n  )\n\n\n# Merge proportions into final dataset\nmerged_data &lt;- race_summary |&gt;\n  select(\n    state, POC_Proportion,\n    proportion_Black, proportion_Hispanic, proportion_Asian,\n    proportion_Native_American, proportion_Other, proportion_White\n  ) |&gt;\n  full_join(state_shootings_summary, by = \"state\") |&gt;\n  full_join(brady_table, by = \"state\")\n\n# Save the updated dataset\nwrite_csv(merged_data, \"dataset/merged_dataset_with_race.csv\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Blog Post 7\n\n\n\n\n\n\n\n\n\n\n\nDec 4, 2024\n\n\nTeam thirteen\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 6\n\n\n\n\n\n\n\n\n\n\n\nNov 16, 2024\n\n\nTeam thirteen\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 5\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2024\n\n\nGroup Thirteen\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 4\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2024\n\n\nGroup thirteen\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 3\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2024\n\n\nGroup Thirteen\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 2\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2024\n\n\nTeam thirteen\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 1\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2024\n\n\nTeam Thirteen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "analysis.html#note-on-attribution",
    "href": "analysis.html#note-on-attribution",
    "title": "Analysis",
    "section": "Note on Attribution",
    "text": "Note on Attribution\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don’t have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don’t need a formal citation.\nIf you are directly quoting from a source, please make that clear. You can show quotes using &gt; like this\n&gt; To be or not to be.\n\nTo be or not to be."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data."
  },
  {
    "objectID": "State_maps.html",
    "href": "State_maps.html",
    "title": "State-Level Heatmaps of POC Proportion and Total Cases",
    "section": "",
    "text": "Shiny applications not supported in static R Markdown documents"
  }
]